# backend/app/services/deepseek_service.py
import httpx
import json
from typing import Dict, Any, Optional
import os
import re
from datetime import datetime
from fastapi import HTTPException
from .prompt_manager import PromptManager

class DeepSeekService:
    """DeepSeek APIæœåŠ¡ç±»ï¼Œç”¨äºç”Ÿæˆè¯¦ç»†çš„å…«å­—è¿åŠ¿è§£è¯»"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡æˆ– .env æ–‡ä»¶åŠ è½½DeepSeek APIé…ç½®
        self.api_key = os.getenv("DEEPSEEK_API_KEY", "")
        self.base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
        self.model = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
        self.timeout = float(os.getenv("DEEPSEEK_TIMEOUT", "30"))  # å¢åŠ åˆ°30ç§’ï¼Œç»™AIåˆ†ææ›´å¤šæ—¶é—´
        self.temperature = float(os.getenv("DEEPSEEK_TEMPERATURE", "0.7"))
        self.max_tokens = int(os.getenv("DEEPSEEK_MAX_TOKENS", "4096")) # å¢åŠ Tokenä¸Šé™ä»¥å®¹çº³æ›´å¤æ‚çš„JSON
        
        # å…³é—­å¼ºåˆ¶æ¨¡æ‹Ÿæ•°æ®ï¼Œä½¿ç”¨çœŸå®API
        self.force_mock = False
        
        if not self.api_key:
            print("âš ï¸  DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            self.force_mock = True
        else:
            print(f"âœ… DeepSeek API å·²é…ç½® (æ¨¡å‹: {self.model}, æ¸©åº¦: {self.temperature})")
            print(f"ğŸ“¡ APIåœ°å€: {self.base_url}")
            print(f"ğŸ”‘ APIå¯†é’¥: {self.api_key[:10]}...{self.api_key[-4:] if len(self.api_key) > 14 else 'too_short'}")

    async def generate_comprehensive_analysis(self, bazi_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¯¹æ•´ä¸ªå‘½ç›˜çš„å…¨é¢åˆ†æ
        """
        try:
            prompt = PromptManager.generate_comprehensive_analysis_prompt(bazi_data)
            
            if self.api_key and not self.force_mock:
                return await self._call_api_for_structured_json(prompt)
            else:
                # è¿”å›é«˜è´¨é‡çš„æ¨¡æ‹Ÿåˆ†æ
                return self._get_mock_comprehensive_analysis(bazi_data)
                
        except Exception as e:
            print(f"ç”Ÿæˆå…¨é¢åˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {e}")
            # åœ¨çœŸå®é”™è¯¯åœºæ™¯ä¸‹ï¼Œå¯ä»¥è¿”å›ä¸€ä¸ªåŒ…å«é”™è¯¯ä¿¡æ¯çš„æ ‡å‡†ç»“æ„
            return {"error": "Failed to generate comprehensive analysis", "details": str(e)}

    async def generate_dayun_analysis(self, bazi_data: Dict[str, Any], dayun_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¯¹ç‰¹å®šå¤§è¿å‘¨æœŸçš„æ·±å…¥åˆ†æ
        """
        try:
            prompt = PromptManager.generate_dayun_analysis_prompt(bazi_data, dayun_info)
            
            if self.api_key and not self.force_mock:
                return await self._call_api_for_structured_json(prompt)
            else:
                return self._get_mock_dayun_analysis(dayun_info)
                
        except Exception as e:
            print(f"ç”Ÿæˆå¤§è¿æ·±åº¦åˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {"error": "Failed to generate Dayun analysis", "details": str(e)}

    async def generate_liunian_analysis(self, bazi_data: Dict[str, Any], year: int) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¯¹ç‰¹å®šæµå¹´çš„æ·±å…¥åˆ†æ
        """
        try:
            prompt = PromptManager.generate_liunian_analysis_prompt(bazi_data, year)
            
            if self.api_key and not self.force_mock:
                return await self._call_api_for_structured_json(prompt)
            else:
                return self._get_mock_liunian_analysis(year)
                
        except Exception as e:
            print(f"ç”Ÿæˆæµå¹´åˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {"error": "Failed to generate Liunian analysis", "details": str(e)}

    async def generate_detailed_fortune_analysis(self, bazi_data: Dict[str, Any], year: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆè¯¦ç»†çš„æµå¹´è¿åŠ¿åˆ†æï¼Œç»“åˆç»¼åˆåˆ†æå’Œæµå¹´åˆ†æ
        """
        try:
            year_int = int(year)
            
            # å¦‚æœæœ‰APIå¯†é’¥ä¸”æœªå¼ºåˆ¶æ¨¡æ‹Ÿï¼Œè°ƒç”¨çœŸå®API
            if self.api_key and not self.force_mock:
                # ä½¿ç”¨æµå¹´åˆ†ææç¤ºè¯
                prompt = PromptManager.generate_liunian_analysis_prompt(bazi_data, year_int)
                return await self._call_api_for_structured_json(prompt)
            else:
                # è¿”å›æ¨¡æ‹Ÿçš„è¯¦ç»†è¿åŠ¿åˆ†æ
                return self._get_mock_detailed_fortune_analysis(bazi_data, year_int)
                
        except Exception as e:
            print(f"ç”Ÿæˆè¯¦ç»†è¿åŠ¿åˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {"error": "Failed to generate detailed fortune analysis", "details": str(e)}

    async def _call_api_for_structured_json(self, prompt: str) -> Dict[str, Any]:
        """
        è°ƒç”¨ LLM API å¹¶ç¡®ä¿è¿”å›ç»“æ„åŒ–çš„ JSONã€‚
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # ä½¿ç”¨ response_format å¼ºåˆ¶ JSON è¾“å‡º
        data = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": PromptManager.get_master_persona_prompt()},
                {"role": "user", "content": prompt}
            ],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "response_format": {"type": "json_object"} # å¼ºåˆ¶JSONè¾“å‡º
        }
        
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            try:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=data
                )
                response.raise_for_status()  # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 2xxï¼Œåˆ™å¼•å‘å¼‚å¸¸
                
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # ç”±äºå·²ä½¿ç”¨json_objectæ¨¡å¼ï¼Œå¯ä»¥ç›´æ¥è§£æ
                return json.loads(content)

            except httpx.HTTPStatusError as e:
                print(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {e.response.status_code}, å“åº”: {e.response.text}")
                raise HTTPException(
                    status_code=e.response.status_code,
                    detail=f"LLM API call failed: {e.response.text}"
                )
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON è§£æå¤±è´¥: {e}")
                print(f"åŸå§‹å“åº”: {content[:500]}...")
                # å³ä½¿åœ¨json_objectæ¨¡å¼ä¸‹ï¼Œä¹Ÿå¯èƒ½å‡ºç°æ„å¤–çš„éJSONå“åº”
                return {"error": "Failed to parse LLM response as JSON", "raw_response": content}
            except Exception as e:
                print(f"è°ƒç”¨LLM APIæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                raise HTTPException(status_code=500, detail=f"An unexpected error occurred with the LLM service: {e}")

    # === MOCK DATA METHODS ===

    def _get_mock_comprehensive_analysis(self, bazi_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„å…¨é¢åˆ†æ"""
        return {
            "personality_analysis": {
                "summary": "å‘½ä¸»æ€§æ ¼ç¨³é‡ï¼Œå¯Œæœ‰è´£ä»»å¿ƒï¼Œä½†æœ‰æ—¶ç•¥æ˜¾å›ºæ‰§ã€‚",
                "strengths": "è¯šä¿¡ã€å¯é ã€æœ‰æ¯…åŠ›ã€‚",
                "weaknesses": "ç¼ºä¹çµæ´»æ€§ã€ä¸å–„å˜é€šã€‚"
            },
            "life_pattern": {
                "summary": "ä¸€ç”Ÿè¿åŠ¿å¹³ç¨³ï¼Œä¸­å¹´åå¼€å§‹èµ°ä¸Šå¡è·¯ã€‚",
                "favorable_elements_guidance": "å®œå¤šç”¨äº”è¡Œâ€œé‡‘â€å’Œâ€œæ°´â€ç›¸å…³çš„é¢œè‰²ï¼ˆç™½ã€è“ã€é»‘ï¼‰ã€æ–¹ä½ï¼ˆè¥¿ã€åŒ—ï¼‰å’Œè¡Œä¸šï¼ˆé‡‘èã€è´¸æ˜“ï¼‰ã€‚"
            },
            # ... å…¶ä»–éƒ¨åˆ†çš„æ¨¡æ‹Ÿæ•°æ® ...
        }

    def _get_mock_dayun_analysis(self, dayun_info: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„å¤§è¿åˆ†æ"""
        return {
            "dayun_overview": {
                "summary": f"æ­¤ {dayun_info.get('gan_zhi', '')} å¤§è¿æ˜¯äººç”Ÿçš„é‡è¦è½¬æŠ˜æœŸã€‚",
                "score": "85",
                "key_themes": ["äº‹ä¸šçªç ´", "è´¢å¯Œå¢é•¿"]
            },
            # ... å…¶ä»–éƒ¨åˆ†çš„æ¨¡æ‹Ÿæ•°æ® ...
        }

    def _get_mock_liunian_analysis(self, year: int) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„æµå¹´åˆ†æ"""
        return {
            "liunian_overview": {
                "summary": f"{year}å¹´æ˜¯å……æ»¡æœºé‡çš„ä¸€å¹´ï¼Œä½†ä¹Ÿä¼´éšç€æŒ‘æˆ˜ã€‚",
                "score": "75",
                "key_themes": ["å­¦ä¹ æˆé•¿", "äººé™…å…³ç³»"]
            },
            "monthly_fortune": [{"month": i, "fortune": f"{i}æœˆè¿åŠ¿å¹³ç¨³", "advice": "é¡ºå…¶è‡ªç„¶"} for i in range(1, 13)],
            # ... å…¶ä»–éƒ¨åˆ†çš„æ¨¡æ‹Ÿæ•°æ® ...
        }

    def _get_mock_detailed_fortune_analysis(self, bazi_data: Dict[str, Any], year: int) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„è¯¦ç»†è¿åŠ¿åˆ†æ"""
        return {
            "detailed_fortune_overview": {
                "year": year,
                "summary": f"{year}å¹´æ˜¯æ‚¨äººç”Ÿä¸­çš„é‡è¦è½¬æŠ˜å¹´ä»½ï¼Œæœºé‡ä¸æŒ‘æˆ˜å¹¶å­˜ã€‚",
                "overall_score": "78",
                "key_themes": ["äº‹ä¸šå‘å±•", "è´¢å¯Œå¢é•¿", "äººé™…å…³ç³»", "å¥åº·è°ƒç†"]
            },
            "monthly_fortune": [
                {
                    "month": i,
                    "fortune_score": 70 + (i % 3) * 5,
                    "summary": f"{i}æœˆè¿åŠ¿{'ä¸Šå‡' if i % 2 == 0 else 'å¹³ç¨³'}",
                    "advice": f"{i}æœˆå®œ{'ç§¯æè¿›å–' if i % 2 == 0 else 'ç¨³å¥ä¿å®ˆ'}"
                } for i in range(1, 13)
            ],
            "career_analysis": {
                "summary": f"{year}å¹´äº‹ä¸šè¿åŠ¿æ•´ä½“å‘å¥½ï¼Œæœ‰æ™‹å‡æœºä¼šã€‚",
                "key_opportunities": ["é¡¹ç›®åˆä½œ", "æŠ€èƒ½æå‡", "äººè„‰æ‹“å±•"],
                "challenges": ["ç«äº‰æ¿€çƒˆ", "å‹åŠ›å¢å¤§"],
                "advice": "æŠŠæ¡æœºé‡ï¼Œç¨³æ­¥å‰è¿›"
            },
            "wealth_analysis": {
                "summary": f"{year}å¹´è´¢è¿ç¨³ä¸­æœ‰å‡ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚",
                "income_forecast": "æ­£è´¢è¿ä½³ï¼Œåè´¢è¿ä¸€èˆ¬",
                "investment_advice": "ä¿å®ˆæŠ•èµ„ï¼Œé¿å…é«˜é£é™©é¡¹ç›®",
                "favorable_periods": ["3-5æœˆ", "9-11æœˆ"]
            },
            "relationship_analysis": {
                "summary": f"{year}å¹´äººé™…å…³ç³»å’Œè°ï¼Œæ„Ÿæƒ…ç”Ÿæ´»ç¾æ»¡ã€‚",
                "love_fortune": "å•èº«è€…æœ‰æ¡ƒèŠ±è¿ï¼Œå·²å©šè€…æ„Ÿæƒ…ç¨³å®š",
                "family_relations": "å®¶åº­å’Œç¦ï¼Œé•¿è¾ˆå…³çˆ±",
                "social_network": "è´µäººç›¸åŠ©ï¼Œäººè„‰æ‹“å±•"
            },
            "health_analysis": {
                "summary": f"{year}å¹´å¥åº·çŠ¶å†µè‰¯å¥½ï¼Œéœ€æ³¨æ„é¢„é˜²ã€‚",
                "physical_health": "ä½“è´¨å¢å¼ºï¼Œç²¾åŠ›å……æ²›",
                "mental_health": "å¿ƒç†å¹³è¡¡ï¼Œå‹åŠ›å¯æ§",
                "prevention_advice": "å®šæœŸä½“æ£€ï¼Œåˆç†ä½œæ¯"
            },
            "lucky_elements": {
                "colors": ["è“è‰²", "ç»¿è‰²", "ç™½è‰²"],
                "numbers": [1, 6, 8],
                "directions": ["åŒ—æ–¹", "ä¸œæ–¹"],
                "months": ["3æœˆ", "7æœˆ", "10æœˆ"]
            },
            "annual_suggestions": [
                "æŠŠæ¡æœºé‡ï¼Œå‹‡äºåˆ›æ–°",
                "æ³¨é‡å¥åº·ï¼Œå¹³è¡¡å·¥ä½œç”Ÿæ´»",
                "ç»´æŠ¤äººé™…å…³ç³»ï¼Œæ‰©å¤§ç¤¾äº¤åœˆ",
                "ç†æ€§æŠ•èµ„ï¼Œç§¯ç´¯è´¢å¯Œ"
            ],
            "analysis_metadata": {
                "generation_time": datetime.now().isoformat(),
                "analysis_type": "detailed_fortune_mock",
                "bazi_elements": bazi_data.get("day_master_element", "æœªçŸ¥")
            }
        }


# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
deepseek_service = DeepSeekService()
